{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36895663",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sound_classification_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce38fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_model = pickle.load(open('sound_classification_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5d64504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.2320,  0.6700,  0.2891,  ...,  0.0316,  0.4621,  0.5305],\n",
      "         [-0.5503,  0.1242,  0.3748,  ...,  0.3358,  0.1445,  0.4761],\n",
      "         [-0.3932,  0.4798,  0.3261,  ..., -0.1323,  0.0590, -0.1956],\n",
      "         ...,\n",
      "         [-0.5741, -0.5741, -0.5741,  ..., -0.5741, -0.5741, -0.5741],\n",
      "         [-0.5741, -0.5741, -0.5741,  ..., -0.5741, -0.5741, -0.5741],\n",
      "         [-0.5741, -0.5741, -0.5741,  ..., -0.5741, -0.5741, -0.5741]],\n",
      "\n",
      "        [[ 0.5425,  0.6041,  0.4553,  ..., -0.5061,  0.5165,  0.3901],\n",
      "         [ 0.1324,  0.2135,  0.5705,  ..., -0.1682,  0.1633,  0.4532],\n",
      "         [-0.5741,  0.6044,  0.3165,  ..., -0.3917,  0.3423, -0.1641],\n",
      "         ...,\n",
      "         [-0.5741, -0.5741, -0.5741,  ..., -0.5741, -0.5741, -0.5741],\n",
      "         [-0.5741, -0.5741, -0.5741,  ..., -0.5741, -0.5741, -0.5741],\n",
      "         [-0.5741, -0.5741, -0.5741,  ..., -0.5741, -0.5741, -0.5741]]],\n",
      "       device='cuda:0')\n",
      "tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "def inference (model, data):\n",
    "  correct_prediction = 0\n",
    "  total_prediction = 0\n",
    "\n",
    "  # Disable gradient updates\n",
    "  with torch.no_grad():\n",
    "      # Get the input features and target labels, and put them on the GPU\n",
    "      data_1 = data[0].clone().detach()\n",
    "      data_2 = torch.Tensor(data[1])\n",
    "      inputs = data_1.to(device)\n",
    "      label = data_2.to(device)\n",
    "\n",
    "      # Normalize the inputs\n",
    "      inputs_m, inputs_s = inputs.float().mean(), inputs.std()\n",
    "      inputs = (inputs - inputs_m) / inputs_s\n",
    "      print(inputs)\n",
    "      # Get predictions\n",
    "      model.to(device)\n",
    "      outputs = model(inputs.unsqueeze(0))\n",
    "\n",
    "      # Get the predicted class with the highest score\n",
    "      _, prediction = torch.max(outputs,1)\n",
    "    \n",
    "  #acc = correct_prediction/total_prediction\n",
    "  print(prediction)\n",
    "\n",
    "# Run inference on trained model with the validation set\n",
    "inference(external_model, processed_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d4d51",
   "metadata": {},
   "source": [
    "# Manipulate LSAFEV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d662d5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc15.1</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "      <th>file_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambulance142.wav</td>\n",
       "      <td>0.345168</td>\n",
       "      <td>0.308853</td>\n",
       "      <td>1287.145377</td>\n",
       "      <td>1261.699532</td>\n",
       "      <td>2379.211895</td>\n",
       "      <td>0.081083</td>\n",
       "      <td>-74.003632</td>\n",
       "      <td>163.974854</td>\n",
       "      <td>-72.760811</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.421668</td>\n",
       "      <td>-2.059879</td>\n",
       "      <td>9.900706</td>\n",
       "      <td>6.835095</td>\n",
       "      <td>2.545403</td>\n",
       "      <td>-4.973841</td>\n",
       "      <td>4.305125</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambulance449.wav</td>\n",
       "      <td>0.386696</td>\n",
       "      <td>0.263407</td>\n",
       "      <td>2223.479605</td>\n",
       "      <td>2115.848084</td>\n",
       "      <td>4718.463135</td>\n",
       "      <td>0.122690</td>\n",
       "      <td>10.772755</td>\n",
       "      <td>101.783501</td>\n",
       "      <td>-41.391842</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.581450</td>\n",
       "      <td>-8.168453</td>\n",
       "      <td>1.215980</td>\n",
       "      <td>-9.383577</td>\n",
       "      <td>1.723579</td>\n",
       "      <td>0.454906</td>\n",
       "      <td>9.782359</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ambulance888.wav</td>\n",
       "      <td>0.517708</td>\n",
       "      <td>0.281876</td>\n",
       "      <td>1393.990435</td>\n",
       "      <td>1586.770873</td>\n",
       "      <td>2898.286321</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>-52.157757</td>\n",
       "      <td>144.876480</td>\n",
       "      <td>-45.382484</td>\n",
       "      <td>...</td>\n",
       "      <td>7.127768</td>\n",
       "      <td>2.115508</td>\n",
       "      <td>1.014645</td>\n",
       "      <td>-0.404026</td>\n",
       "      <td>3.214492</td>\n",
       "      <td>-5.129189</td>\n",
       "      <td>0.641621</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ambulance474.wav</td>\n",
       "      <td>0.229988</td>\n",
       "      <td>0.184972</td>\n",
       "      <td>2211.761868</td>\n",
       "      <td>1923.778124</td>\n",
       "      <td>3913.245568</td>\n",
       "      <td>0.116267</td>\n",
       "      <td>-130.663757</td>\n",
       "      <td>88.106293</td>\n",
       "      <td>-45.787319</td>\n",
       "      <td>...</td>\n",
       "      <td>24.814060</td>\n",
       "      <td>10.781730</td>\n",
       "      <td>-1.599966</td>\n",
       "      <td>-20.135389</td>\n",
       "      <td>-10.052261</td>\n",
       "      <td>-3.237577</td>\n",
       "      <td>11.093946</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ambulance305.wav</td>\n",
       "      <td>0.149670</td>\n",
       "      <td>0.115018</td>\n",
       "      <td>1266.959915</td>\n",
       "      <td>1654.095586</td>\n",
       "      <td>1831.978666</td>\n",
       "      <td>0.094191</td>\n",
       "      <td>-213.125717</td>\n",
       "      <td>138.419174</td>\n",
       "      <td>-6.672751</td>\n",
       "      <td>...</td>\n",
       "      <td>9.291833</td>\n",
       "      <td>4.321001</td>\n",
       "      <td>5.267659</td>\n",
       "      <td>-1.062411</td>\n",
       "      <td>-0.764217</td>\n",
       "      <td>-4.817847</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           filename  chroma_stft  spectral_centroid  spectral_bandwidth  \\\n",
       "0  ambulance142.wav     0.345168           0.308853         1287.145377   \n",
       "1  ambulance449.wav     0.386696           0.263407         2223.479605   \n",
       "2  ambulance888.wav     0.517708           0.281876         1393.990435   \n",
       "3  ambulance474.wav     0.229988           0.184972         2211.761868   \n",
       "4  ambulance305.wav     0.149670           0.115018         1266.959915   \n",
       "\n",
       "       rolloff  zero_crossing_rate     mfcc1       mfcc2       mfcc3  \\\n",
       "0  1261.699532         2379.211895  0.081083  -74.003632  163.974854   \n",
       "1  2115.848084         4718.463135  0.122690   10.772755  101.783501   \n",
       "2  1586.770873         2898.286321  0.064444  -52.157757  144.876480   \n",
       "3  1923.778124         3913.245568  0.116267 -130.663757   88.106293   \n",
       "4  1654.095586         1831.978666  0.094191 -213.125717  138.419174   \n",
       "\n",
       "       mfcc4  ...     mfcc15   mfcc15.1    mfcc16     mfcc17     mfcc18  \\\n",
       "0 -72.760811  ...  -2.421668  -2.059879  9.900706   6.835095   2.545403   \n",
       "1 -41.391842  ...  -5.581450  -8.168453  1.215980  -9.383577   1.723579   \n",
       "2 -45.382484  ...   7.127768   2.115508  1.014645  -0.404026   3.214492   \n",
       "3 -45.787319  ...  24.814060  10.781730 -1.599966 -20.135389 -10.052261   \n",
       "4  -6.672751  ...   9.291833   4.321001  5.267659  -1.062411  -0.764217   \n",
       "\n",
       "     mfcc19     mfcc20      label         file_path  classID  \n",
       "0 -4.973841   4.305125  Ambulance  //ambulance_data        1  \n",
       "1  0.454906   9.782359  Ambulance  //ambulance_data        1  \n",
       "2 -5.129189   0.641621  Ambulance  //ambulance_data        1  \n",
       "3 -3.237577  11.093946  Ambulance  //ambulance_data        1  \n",
       "4 -4.817847   0.678133  Ambulance  //ambulance_data        1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ambulance = pd.read_csv('D://Thesis//Emergency Priority//dataset//Ambulance_final.csv')\n",
    "ambulance['file_path'] = '//ambulance_data'\n",
    "ambulance['classID'] = \"1\"\n",
    "ambulance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17836667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc15.1</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "      <th>file_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>road324.wav</td>\n",
       "      <td>0.442203</td>\n",
       "      <td>0.022001</td>\n",
       "      <td>2545.346793</td>\n",
       "      <td>2426.479510</td>\n",
       "      <td>4754.282790</td>\n",
       "      <td>0.155189</td>\n",
       "      <td>-270.384613</td>\n",
       "      <td>100.619019</td>\n",
       "      <td>-10.223790</td>\n",
       "      <td>...</td>\n",
       "      <td>18.793995</td>\n",
       "      <td>-5.305555</td>\n",
       "      <td>-0.965415</td>\n",
       "      <td>5.482495</td>\n",
       "      <td>-10.139045</td>\n",
       "      <td>-2.003446</td>\n",
       "      <td>3.736357</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road508.wav</td>\n",
       "      <td>0.337758</td>\n",
       "      <td>0.206505</td>\n",
       "      <td>3470.430019</td>\n",
       "      <td>2706.420324</td>\n",
       "      <td>6899.114051</td>\n",
       "      <td>0.181979</td>\n",
       "      <td>11.297463</td>\n",
       "      <td>41.953815</td>\n",
       "      <td>-35.142498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.847138</td>\n",
       "      <td>-7.962325</td>\n",
       "      <td>-2.489496</td>\n",
       "      <td>-5.065870</td>\n",
       "      <td>15.039159</td>\n",
       "      <td>-7.175189</td>\n",
       "      <td>2.037403</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>road351.wav</td>\n",
       "      <td>0.440022</td>\n",
       "      <td>0.173755</td>\n",
       "      <td>1248.230706</td>\n",
       "      <td>1904.995271</td>\n",
       "      <td>2556.032621</td>\n",
       "      <td>0.020921</td>\n",
       "      <td>-134.684311</td>\n",
       "      <td>138.695663</td>\n",
       "      <td>-9.734646</td>\n",
       "      <td>...</td>\n",
       "      <td>9.100524</td>\n",
       "      <td>3.403701</td>\n",
       "      <td>8.452733</td>\n",
       "      <td>1.088790</td>\n",
       "      <td>4.929297</td>\n",
       "      <td>-0.253739</td>\n",
       "      <td>4.125893</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>road703.wav</td>\n",
       "      <td>0.600494</td>\n",
       "      <td>0.040601</td>\n",
       "      <td>1075.899022</td>\n",
       "      <td>1827.481394</td>\n",
       "      <td>1814.793513</td>\n",
       "      <td>0.032874</td>\n",
       "      <td>-252.906036</td>\n",
       "      <td>157.615418</td>\n",
       "      <td>9.920370</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136444</td>\n",
       "      <td>-3.741317</td>\n",
       "      <td>3.954798</td>\n",
       "      <td>-0.935155</td>\n",
       "      <td>8.923501</td>\n",
       "      <td>3.227440</td>\n",
       "      <td>6.275182</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>road681.wav</td>\n",
       "      <td>0.631075</td>\n",
       "      <td>0.065356</td>\n",
       "      <td>742.548260</td>\n",
       "      <td>1372.708521</td>\n",
       "      <td>1231.119479</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>-257.946930</td>\n",
       "      <td>187.372162</td>\n",
       "      <td>7.777202</td>\n",
       "      <td>...</td>\n",
       "      <td>7.443036</td>\n",
       "      <td>-0.647730</td>\n",
       "      <td>2.444229</td>\n",
       "      <td>-2.062293</td>\n",
       "      <td>6.974404</td>\n",
       "      <td>1.464423</td>\n",
       "      <td>2.268083</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename  chroma_stft  spectral_centroid  spectral_bandwidth  \\\n",
       "0  road324.wav     0.442203           0.022001         2545.346793   \n",
       "1  road508.wav     0.337758           0.206505         3470.430019   \n",
       "2  road351.wav     0.440022           0.173755         1248.230706   \n",
       "3  road703.wav     0.600494           0.040601         1075.899022   \n",
       "4  road681.wav     0.631075           0.065356          742.548260   \n",
       "\n",
       "       rolloff  zero_crossing_rate     mfcc1       mfcc2       mfcc3  \\\n",
       "0  2426.479510         4754.282790  0.155189 -270.384613  100.619019   \n",
       "1  2706.420324         6899.114051  0.181979   11.297463   41.953815   \n",
       "2  1904.995271         2556.032621  0.020921 -134.684311  138.695663   \n",
       "3  1827.481394         1814.793513  0.032874 -252.906036  157.615418   \n",
       "4  1372.708521         1231.119479  0.023869 -257.946930  187.372162   \n",
       "\n",
       "       mfcc4  ...     mfcc15  mfcc15.1    mfcc16    mfcc17     mfcc18  \\\n",
       "0 -10.223790  ...  18.793995 -5.305555 -0.965415  5.482495 -10.139045   \n",
       "1 -35.142498  ...  -0.847138 -7.962325 -2.489496 -5.065870  15.039159   \n",
       "2  -9.734646  ...   9.100524  3.403701  8.452733  1.088790   4.929297   \n",
       "3   9.920370  ...   1.136444 -3.741317  3.954798 -0.935155   8.923501   \n",
       "4   7.777202  ...   7.443036 -0.647730  2.444229 -2.062293   6.974404   \n",
       "\n",
       "     mfcc19    mfcc20  label    file_path  classID  \n",
       "0 -2.003446  3.736357   Road  //road_data        0  \n",
       "1 -7.175189  2.037403   Road  //road_data        0  \n",
       "2 -0.253739  4.125893   Road  //road_data        0  \n",
       "3  3.227440  6.275182   Road  //road_data        0  \n",
       "4  1.464423  2.268083   Road  //road_data        0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "road = pd.read_csv('D://Thesis//Emergency Priority//dataset//Road_final.csv')\n",
    "road['file_path'] = '//road_data'\n",
    "road['classID'] = \"0\"\n",
    "road.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3a42133b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc15.1</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>label</th>\n",
       "      <th>file_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambulance142.wav</td>\n",
       "      <td>0.345168</td>\n",
       "      <td>0.308853</td>\n",
       "      <td>1287.145377</td>\n",
       "      <td>1261.699532</td>\n",
       "      <td>2379.211895</td>\n",
       "      <td>0.081083</td>\n",
       "      <td>-74.003632</td>\n",
       "      <td>163.974854</td>\n",
       "      <td>-72.760811</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.421668</td>\n",
       "      <td>-2.059879</td>\n",
       "      <td>9.900706</td>\n",
       "      <td>6.835095</td>\n",
       "      <td>2.545403</td>\n",
       "      <td>-4.973841</td>\n",
       "      <td>4.305125</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambulance449.wav</td>\n",
       "      <td>0.386696</td>\n",
       "      <td>0.263407</td>\n",
       "      <td>2223.479605</td>\n",
       "      <td>2115.848084</td>\n",
       "      <td>4718.463135</td>\n",
       "      <td>0.122690</td>\n",
       "      <td>10.772755</td>\n",
       "      <td>101.783501</td>\n",
       "      <td>-41.391842</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.581450</td>\n",
       "      <td>-8.168453</td>\n",
       "      <td>1.215980</td>\n",
       "      <td>-9.383577</td>\n",
       "      <td>1.723579</td>\n",
       "      <td>0.454906</td>\n",
       "      <td>9.782359</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ambulance888.wav</td>\n",
       "      <td>0.517708</td>\n",
       "      <td>0.281876</td>\n",
       "      <td>1393.990435</td>\n",
       "      <td>1586.770873</td>\n",
       "      <td>2898.286321</td>\n",
       "      <td>0.064444</td>\n",
       "      <td>-52.157757</td>\n",
       "      <td>144.876480</td>\n",
       "      <td>-45.382484</td>\n",
       "      <td>...</td>\n",
       "      <td>7.127768</td>\n",
       "      <td>2.115508</td>\n",
       "      <td>1.014645</td>\n",
       "      <td>-0.404026</td>\n",
       "      <td>3.214492</td>\n",
       "      <td>-5.129189</td>\n",
       "      <td>0.641621</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ambulance474.wav</td>\n",
       "      <td>0.229988</td>\n",
       "      <td>0.184972</td>\n",
       "      <td>2211.761868</td>\n",
       "      <td>1923.778124</td>\n",
       "      <td>3913.245568</td>\n",
       "      <td>0.116267</td>\n",
       "      <td>-130.663757</td>\n",
       "      <td>88.106293</td>\n",
       "      <td>-45.787319</td>\n",
       "      <td>...</td>\n",
       "      <td>24.814060</td>\n",
       "      <td>10.781730</td>\n",
       "      <td>-1.599966</td>\n",
       "      <td>-20.135389</td>\n",
       "      <td>-10.052261</td>\n",
       "      <td>-3.237577</td>\n",
       "      <td>11.093946</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ambulance305.wav</td>\n",
       "      <td>0.149670</td>\n",
       "      <td>0.115018</td>\n",
       "      <td>1266.959915</td>\n",
       "      <td>1654.095586</td>\n",
       "      <td>1831.978666</td>\n",
       "      <td>0.094191</td>\n",
       "      <td>-213.125717</td>\n",
       "      <td>138.419174</td>\n",
       "      <td>-6.672751</td>\n",
       "      <td>...</td>\n",
       "      <td>9.291833</td>\n",
       "      <td>4.321001</td>\n",
       "      <td>5.267659</td>\n",
       "      <td>-1.062411</td>\n",
       "      <td>-0.764217</td>\n",
       "      <td>-4.817847</td>\n",
       "      <td>0.678133</td>\n",
       "      <td>Ambulance</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>road638.wav</td>\n",
       "      <td>0.620770</td>\n",
       "      <td>0.031281</td>\n",
       "      <td>931.578184</td>\n",
       "      <td>1753.522574</td>\n",
       "      <td>1576.478929</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>-311.354034</td>\n",
       "      <td>158.753723</td>\n",
       "      <td>12.853130</td>\n",
       "      <td>...</td>\n",
       "      <td>1.119874</td>\n",
       "      <td>-6.147216</td>\n",
       "      <td>3.674873</td>\n",
       "      <td>-2.406534</td>\n",
       "      <td>3.062174</td>\n",
       "      <td>0.890442</td>\n",
       "      <td>5.863816</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>road323.wav</td>\n",
       "      <td>0.486262</td>\n",
       "      <td>0.086026</td>\n",
       "      <td>2809.751806</td>\n",
       "      <td>2664.180170</td>\n",
       "      <td>5862.207501</td>\n",
       "      <td>0.153611</td>\n",
       "      <td>-60.523140</td>\n",
       "      <td>79.998100</td>\n",
       "      <td>-21.354570</td>\n",
       "      <td>...</td>\n",
       "      <td>7.150903</td>\n",
       "      <td>1.223076</td>\n",
       "      <td>4.254593</td>\n",
       "      <td>-0.084353</td>\n",
       "      <td>0.660076</td>\n",
       "      <td>-2.794935</td>\n",
       "      <td>-0.689680</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>road233.wav</td>\n",
       "      <td>0.722937</td>\n",
       "      <td>0.066561</td>\n",
       "      <td>1218.645216</td>\n",
       "      <td>1738.932865</td>\n",
       "      <td>2446.503155</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>-203.562195</td>\n",
       "      <td>148.460327</td>\n",
       "      <td>-20.818197</td>\n",
       "      <td>...</td>\n",
       "      <td>7.533079</td>\n",
       "      <td>1.822413</td>\n",
       "      <td>5.510491</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>3.786338</td>\n",
       "      <td>1.777025</td>\n",
       "      <td>5.937325</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>road244.wav</td>\n",
       "      <td>0.672640</td>\n",
       "      <td>0.179680</td>\n",
       "      <td>1734.890060</td>\n",
       "      <td>1980.674638</td>\n",
       "      <td>3202.235765</td>\n",
       "      <td>0.078792</td>\n",
       "      <td>-34.751610</td>\n",
       "      <td>124.614510</td>\n",
       "      <td>-38.273533</td>\n",
       "      <td>...</td>\n",
       "      <td>10.895624</td>\n",
       "      <td>1.861239</td>\n",
       "      <td>9.542007</td>\n",
       "      <td>4.217642</td>\n",
       "      <td>7.684665</td>\n",
       "      <td>1.724497</td>\n",
       "      <td>7.023211</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>road171.wav</td>\n",
       "      <td>0.578838</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>2332.891179</td>\n",
       "      <td>2499.648729</td>\n",
       "      <td>4718.463135</td>\n",
       "      <td>0.121141</td>\n",
       "      <td>-385.681427</td>\n",
       "      <td>103.240654</td>\n",
       "      <td>-22.331940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.668734</td>\n",
       "      <td>-6.737777</td>\n",
       "      <td>0.414295</td>\n",
       "      <td>-3.405602</td>\n",
       "      <td>1.418673</td>\n",
       "      <td>-10.597604</td>\n",
       "      <td>-0.588163</td>\n",
       "      <td>Road</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1834 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename  chroma_stft  spectral_centroid  spectral_bandwidth  \\\n",
       "0    ambulance142.wav     0.345168           0.308853         1287.145377   \n",
       "1    ambulance449.wav     0.386696           0.263407         2223.479605   \n",
       "2    ambulance888.wav     0.517708           0.281876         1393.990435   \n",
       "3    ambulance474.wav     0.229988           0.184972         2211.761868   \n",
       "4    ambulance305.wav     0.149670           0.115018         1266.959915   \n",
       "..                ...          ...                ...                 ...   \n",
       "897       road638.wav     0.620770           0.031281          931.578184   \n",
       "898       road323.wav     0.486262           0.086026         2809.751806   \n",
       "899       road233.wav     0.722937           0.066561         1218.645216   \n",
       "900       road244.wav     0.672640           0.179680         1734.890060   \n",
       "901       road171.wav     0.578838           0.003432         2332.891179   \n",
       "\n",
       "         rolloff  zero_crossing_rate     mfcc1       mfcc2       mfcc3  \\\n",
       "0    1261.699532         2379.211895  0.081083  -74.003632  163.974854   \n",
       "1    2115.848084         4718.463135  0.122690   10.772755  101.783501   \n",
       "2    1586.770873         2898.286321  0.064444  -52.157757  144.876480   \n",
       "3    1923.778124         3913.245568  0.116267 -130.663757   88.106293   \n",
       "4    1654.095586         1831.978666  0.094191 -213.125717  138.419174   \n",
       "..           ...                 ...       ...         ...         ...   \n",
       "897  1753.522574         1576.478929  0.023625 -311.354034  158.753723   \n",
       "898  2664.180170         5862.207501  0.153611  -60.523140   79.998100   \n",
       "899  1738.932865         2446.503155  0.029353 -203.562195  148.460327   \n",
       "900  1980.674638         3202.235765  0.078792  -34.751610  124.614510   \n",
       "901  2499.648729         4718.463135  0.121141 -385.681427  103.240654   \n",
       "\n",
       "         mfcc4  ...     mfcc15   mfcc15.1    mfcc16     mfcc17     mfcc18  \\\n",
       "0   -72.760811  ...  -2.421668  -2.059879  9.900706   6.835095   2.545403   \n",
       "1   -41.391842  ...  -5.581450  -8.168453  1.215980  -9.383577   1.723579   \n",
       "2   -45.382484  ...   7.127768   2.115508  1.014645  -0.404026   3.214492   \n",
       "3   -45.787319  ...  24.814060  10.781730 -1.599966 -20.135389 -10.052261   \n",
       "4    -6.672751  ...   9.291833   4.321001  5.267659  -1.062411  -0.764217   \n",
       "..         ...  ...        ...        ...       ...        ...        ...   \n",
       "897  12.853130  ...   1.119874  -6.147216  3.674873  -2.406534   3.062174   \n",
       "898 -21.354570  ...   7.150903   1.223076  4.254593  -0.084353   0.660076   \n",
       "899 -20.818197  ...   7.533079   1.822413  5.510491   0.000635   3.786338   \n",
       "900 -38.273533  ...  10.895624   1.861239  9.542007   4.217642   7.684665   \n",
       "901 -22.331940  ...  -0.668734  -6.737777  0.414295  -3.405602   1.418673   \n",
       "\n",
       "        mfcc19     mfcc20      label         file_path  classID  \n",
       "0    -4.973841   4.305125  Ambulance  //ambulance_data        1  \n",
       "1     0.454906   9.782359  Ambulance  //ambulance_data        1  \n",
       "2    -5.129189   0.641621  Ambulance  //ambulance_data        1  \n",
       "3    -3.237577  11.093946  Ambulance  //ambulance_data        1  \n",
       "4    -4.817847   0.678133  Ambulance  //ambulance_data        1  \n",
       "..         ...        ...        ...               ...      ...  \n",
       "897   0.890442   5.863816       Road       //road_data        0  \n",
       "898  -2.794935  -0.689680       Road       //road_data        0  \n",
       "899   1.777025   5.937325       Road       //road_data        0  \n",
       "900   1.724497   7.023211       Road       //road_data        0  \n",
       "901 -10.597604  -0.588163       Road       //road_data        0  \n",
       "\n",
       "[1834 rows x 30 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_data = pd.concat([ambulance, road])\n",
    "merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ccd526d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data.to_csv('D://Thesis//Emergency Priority//dataset//audio_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e756760",
   "metadata": {},
   "source": [
    "# Import final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8a70e284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>file_path</th>\n",
       "      <th>classID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambulance142.wav</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ambulance449.wav</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ambulance888.wav</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ambulance474.wav</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ambulance305.wav</td>\n",
       "      <td>//ambulance_data</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>road638.wav</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>road323.wav</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>road233.wav</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>road244.wav</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>road171.wav</td>\n",
       "      <td>//road_data</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1834 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename         file_path  classID\n",
       "0     ambulance142.wav  //ambulance_data        1\n",
       "1     ambulance449.wav  //ambulance_data        1\n",
       "2     ambulance888.wav  //ambulance_data        1\n",
       "3     ambulance474.wav  //ambulance_data        1\n",
       "4     ambulance305.wav  //ambulance_data        1\n",
       "...                ...               ...      ...\n",
       "1829       road638.wav       //road_data        0\n",
       "1830       road323.wav       //road_data        0\n",
       "1831       road233.wav       //road_data        0\n",
       "1832       road244.wav       //road_data        0\n",
       "1833       road171.wav       //road_data        0\n",
       "\n",
       "[1834 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read metadata file\n",
    "metadata_file = 'D://Thesis//Emergency Priority//dataset//audio_dataset.csv'\n",
    "df = pd.read_csv(metadata_file)\n",
    "df.head()\n",
    "\n",
    "# Take relevant columns\n",
    "df = df[['filename', 'file_path', 'classID']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "79d22599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ambulance142.wav\n",
       "1       ambulance449.wav\n",
       "2       ambulance888.wav\n",
       "3       ambulance474.wav\n",
       "4       ambulance305.wav\n",
       "              ...       \n",
       "1829         road638.wav\n",
       "1830         road323.wav\n",
       "1831         road233.wav\n",
       "1832         road244.wav\n",
       "1833         road171.wav\n",
       "Name: filename, Length: 1834, dtype: object"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b786d7",
   "metadata": {},
   "source": [
    "# Create Audio Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b4b899b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "\n",
    "class AudioUtil():\n",
    "  # ----------------------------\n",
    "  # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def open(audio_file):\n",
    "    sig, sr = torchaudio.load(audio_file)\n",
    "    return (sig, sr)\n",
    "\n",
    "  # ----------------------------\n",
    "  # Convert the given audio to the desired number of channels\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def rechannel(aud, new_channel):\n",
    "    sig, sr = aud\n",
    "\n",
    "    if (sig.shape[0] == new_channel):\n",
    "      # Nothing to do\n",
    "      return aud\n",
    "\n",
    "    if (new_channel == 1):\n",
    "      # Convert from stereo to mono by selecting only the first channel\n",
    "      resig = sig[:1, :]\n",
    "    else:\n",
    "      # Convert from mono to stereo by duplicating the first channel\n",
    "      resig = torch.cat([sig, sig])\n",
    "\n",
    "    return ((resig, sr))\n",
    "\n",
    "\n",
    "  # ----------------------------\n",
    "  # Since Resample applies to a single channel, we resample one channel at a time\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def resample(aud, newsr):\n",
    "    sig, sr = aud\n",
    "\n",
    "    if (sr == newsr):\n",
    "      # Nothing to do\n",
    "      return aud\n",
    "\n",
    "    num_channels = sig.shape[0]\n",
    "    # Resample first channel\n",
    "    resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "    if (num_channels > 1):\n",
    "      # Resample the second channel and merge both channels\n",
    "      retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "      resig = torch.cat([resig, retwo])\n",
    "\n",
    "    return ((resig, newsr))\n",
    "\n",
    "  # ----------------------------\n",
    "  # Pad (or truncate) the signal to a fixed length 'max_ms' in milliseconds\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def pad_trunc(aud, max_ms):\n",
    "    sig, sr = aud\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr//1000 * max_ms\n",
    "\n",
    "    if (sig_len > max_len):\n",
    "      # Truncate the signal to the given length\n",
    "      sig = sig[:,:max_len]\n",
    "\n",
    "    elif (sig_len < max_len):\n",
    "      # Length of padding to add at the beginning and end of the signal\n",
    "      pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "      pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "      # Pad with 0s\n",
    "      pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "      pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "\n",
    "      sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "      \n",
    "    return (sig, sr)\n",
    "\n",
    "  # ----------------------------\n",
    "  # Shifts the signal to the left or right by some percent. Values at the end\n",
    "  # are 'wrapped around' to the start of the transformed signal.\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def time_shift(aud, shift_limit):\n",
    "    sig,sr = aud\n",
    "    _, sig_len = sig.shape\n",
    "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "    return (sig.roll(shift_amt), sr)\n",
    "\n",
    "\n",
    "  # ----------------------------\n",
    "  # Generate a Spectrogram\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "    sig,sr = aud\n",
    "    top_db = 80\n",
    "\n",
    "    # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "    spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "\n",
    "    # Convert to decibels\n",
    "    spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "    return (spec)\n",
    "\n",
    "  # ----------------------------\n",
    "  # Augment the Spectrogram by masking out some sections of it in both the frequency\n",
    "  # dimension (ie. horizontal bars) and the time dimension (vertical bars) to prevent\n",
    "  # overfitting and to help the model generalise better. The masked sections are\n",
    "  # replaced with the mean value.\n",
    "  # ----------------------------\n",
    "  @staticmethod\n",
    "  def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "    _, n_mels, n_steps = spec.shape\n",
    "    mask_value = spec.mean()\n",
    "    aug_spec = spec\n",
    "\n",
    "    freq_mask_param = max_mask_pct * n_mels\n",
    "    for _ in range(n_freq_masks):\n",
    "      aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    time_mask_param = max_mask_pct * n_steps\n",
    "    for _ in range(n_time_masks):\n",
    "      aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "\n",
    "    return aug_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6902a1f",
   "metadata": {},
   "source": [
    "# Create Dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2af1038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchaudio\n",
    "\n",
    "# ----------------------------\n",
    "# Sound Dataset\n",
    "# ----------------------------\n",
    "class AudioDS(Dataset):\n",
    "  def __init__(self, df, data_path):\n",
    "    self.df = df\n",
    "    self.data_path = str(data_path)\n",
    "    self.duration = 4000\n",
    "    self.sr = 44100\n",
    "    self.channel = 2\n",
    "    self.shift_pct = 0.4\n",
    "            \n",
    "  # ----------------------------\n",
    "  # Number of items in dataset\n",
    "  # ----------------------------\n",
    "  def __len__(self):\n",
    "    return len(self.df)    \n",
    "    \n",
    "  # ----------------------------\n",
    "  # Get i'th item in dataset\n",
    "  # ----------------------------\n",
    "  def __getitem__(self, idx):\n",
    "    # Absolute file path of the audio file - concatenate the audio directory with\n",
    "    # the relative path\n",
    "    audio_file = self.data_path + self.df.loc[idx,'file_path'] + '//' + self.df.loc[idx,'filename']\n",
    "    #self.data_path + self.df.loc[idx, 'relative_path']\n",
    "    # Get the Class ID\n",
    "    class_id = self.df.loc[idx, 'classID']\n",
    "\n",
    "    aud = AudioUtil.open(audio_file)\n",
    "    \n",
    "    reaud = AudioUtil.resample(aud, self.sr)\n",
    "    rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "\n",
    "    dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "    shift_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "    return aug_sgram, class_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ada6c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "data_path = 'D://Thesis//Emergency Priority//dataset'\n",
    "data_set = AudioDS(df, data_path)\n",
    "\n",
    "\n",
    "# Random split of 80:20 between training and validation\n",
    "num_items = len(data_set)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(data_set, [num_train, num_val])\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ca423",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0a539124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "import torch.nn as nn\n",
    "\n",
    "# ----------------------------\n",
    "# Audio Classification Model\n",
    "# ----------------------------\n",
    "class AudioClassifier (nn.Module):\n",
    "    # ----------------------------\n",
    "    # Build the model architecture\n",
    "    # ----------------------------\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Third Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Fourth Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Final output\n",
    "        return x\n",
    "\n",
    "# Create the model and put it on the GPU if available\n",
    "model = AudioClassifier()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "# Check that it is on Cuda\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab755efa",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4a928acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Training Start ----------------------\n",
      "Epoch: 0, Loss: 0.30, Accuracy: 0.94\n",
      "Epoch: 1, Loss: 0.27, Accuracy: 0.94\n",
      "Epoch: 2, Loss: 0.22, Accuracy: 0.94\n",
      "Epoch: 3, Loss: 0.18, Accuracy: 0.94\n",
      "Epoch: 4, Loss: 0.18, Accuracy: 0.94\n",
      "Epoch: 5, Loss: 0.15, Accuracy: 0.95\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "def training(model, train_dl, num_epochs):\n",
    "  # Loss Function, Optimizer and Scheduler\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "  scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "    \n",
    "  print(\"--------------------- Training Start ----------------------\")\n",
    "  # Repeat for each epoch\n",
    "  for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    # Repeat for each batch in the training set\n",
    "    for i, data in enumerate(train_dl):\n",
    "        # Get the input features and target labels, and put them on the GPU\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # Normalize the inputs\n",
    "        inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "        inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        model = model.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Keep stats for Loss and Accuracy\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Get the predicted class with the highest score\n",
    "        _, prediction = torch.max(outputs,1)\n",
    "        # Count of predictions that matched the target label\n",
    "        correct_prediction += (prediction == labels).sum().item()\n",
    "        total_prediction += prediction.shape[0]\n",
    "\n",
    "        #if i % 10 == 0:    # print every 10 mini-batches\n",
    "        #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "    \n",
    "    # Print stats at the end of the epoch\n",
    "    num_batches = len(train_dl)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "  print('Finished Training')\n",
    "  \n",
    "num_epochs=6\n",
    "training(model, train_dl, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ce982",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "39437132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "label tensor([0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0], device='cuda:0')\n",
      "pred: tensor([1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "label tensor([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "pred: tensor([0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "label tensor([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1], device='cuda:0')\n",
      "pred: tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "label tensor([0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n",
      "pred: tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "label tensor([1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "pred: tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "label tensor([0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "pred: tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "label tensor([1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0], device='cuda:0')\n",
      "pred: tensor([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "label tensor([1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "pred: tensor([1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1], device='cuda:0')\n",
      "label tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "pred: tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "label tensor([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "pred: tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "label tensor([1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1], device='cuda:0')\n",
      "pred: tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "label tensor([0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "pred: tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1], device='cuda:0')\n",
      "label tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1], device='cuda:0')\n",
      "pred: tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "label tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "pred: tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "label tensor([1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0], device='cuda:0')\n",
      "pred: tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "label tensor([0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "pred: tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "label tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "pred: tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "label tensor([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "pred: tensor([1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0], device='cuda:0')\n",
      "label tensor([1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1], device='cuda:0')\n",
      "pred: tensor([0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "label tensor([0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "pred: tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "label tensor([0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0], device='cuda:0')\n",
      "pred: tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "label tensor([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0], device='cuda:0')\n",
      "pred: tensor([1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "label tensor([0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1], device='cuda:0')\n",
      "Accuracy: 0.95, Total items: 367\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "def inference (model, val_dl):\n",
    "  correct_prediction = 0\n",
    "  total_prediction = 0\n",
    "\n",
    "  # Disable gradient updates\n",
    "  with torch.no_grad():\n",
    "    for data in val_dl:\n",
    "      # Get the input features and target labels, and put them on the GPU\n",
    "      inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "      # Normalize the inputs\n",
    "      inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "      inputs = (inputs - inputs_m) / inputs_s\n",
    "      # Get predictions\n",
    "      outputs = model(inputs)\n",
    "\n",
    "      # Get the predicted class with the highest score\n",
    "      _, prediction = torch.max(outputs,1)\n",
    "      # Count of predictions that matched the target label\n",
    "      correct_prediction += (prediction == labels).sum().item()\n",
    "      total_prediction += prediction.shape[0]\n",
    "      print('pred:', prediction)\n",
    "      print('label', labels)\n",
    "    \n",
    "  acc = correct_prediction/total_prediction\n",
    "  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "\n",
    "# Run inference on trained model with the validation set\n",
    "inference(model, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56c96d7",
   "metadata": {},
   "source": [
    "# Feed Single Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b3336485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 27.3107,  26.5599,  27.9763,  ...,  16.6296,  20.8776,  22.9111],\n",
      "         [ 21.3255,  26.8543,  26.9987,  ...,  17.7892,  21.2407,  20.1065],\n",
      "         [ 11.5656,  22.1966,  21.3494,  ...,  13.9362,  14.4440,  13.6754],\n",
      "         ...,\n",
      "         [-32.9196, -39.4222, -39.4222,  ..., -39.4222, -39.4222, -39.4222],\n",
      "         [-32.8102, -39.4222, -39.4222,  ..., -39.4222, -39.4222, -39.4222],\n",
      "         [-32.6616, -39.4222, -39.4222,  ..., -39.4222, -39.4222, -39.4222]],\n",
      "\n",
      "        [[ 26.3468,  24.9435,  26.2747,  ...,  18.3665,  22.9581,  24.6786],\n",
      "         [ 20.6083,  24.2898,  25.0454,  ...,  20.5707,  24.0757,  21.1878],\n",
      "         [ 12.6996,  18.0171,  18.0091,  ...,  18.6834,  19.7146,  18.8760],\n",
      "         ...,\n",
      "         [-31.2711, -39.4222, -39.4222,  ..., -39.4222, -39.4222, -39.4222],\n",
      "         [-31.3844, -39.4222, -39.4222,  ..., -39.4222, -39.4222, -39.4222],\n",
      "         [-31.2421, -39.4222, -39.4222,  ..., -39.4222, -39.4222, -39.4222]]]), 0)\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "\n",
    "data_path = 'D://Thesis//Emergency Priority//dataset//road_data//road34.wav'\n",
    "sig, sr = torchaudio.load(data_path)\n",
    "\n",
    "Audio(sig.numpy()[0], rate=sr)\n",
    "\n",
    "def process_audio(audio):\n",
    "    \n",
    "    duration = 4000\n",
    "    sr = 44100\n",
    "    channel = 2\n",
    "    shift_pct = 0.4\n",
    "    class_id = 0 #siren is 7\n",
    "    \n",
    "    #audio_file = self.data_path + self.df.loc[idx,'file_path'] + '//' + self.df.loc[idx,'filename']\n",
    "    #self.data_path + self.df.loc[idx, 'relative_path']\n",
    "    # Get the Class ID\n",
    "    #class_id = self.df.loc[idx, 'classID']\n",
    "\n",
    "    aud = AudioUtil.open(audio)\n",
    "    \n",
    "    reaud = AudioUtil.resample(aud, sr)\n",
    "    rechan = AudioUtil.rechannel(reaud, channel)\n",
    "\n",
    "    #dur_aud = AudioUtil.pad_trunc(rechan, duration)\n",
    "    shift_aud = AudioUtil.time_shift(rechan, shift_pct)\n",
    "    sgram = AudioUtil.spectro_gram(shift_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "    aug_sgram = AudioUtil.spectro_augment(sgram, max_mask_pct=0.1, n_freq_masks=2, n_time_masks=2)\n",
    "\n",
    "    return aug_sgram, class_id\n",
    "\n",
    "processed_audio = process_audio(data_path)\n",
    "print(processed_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "0d2c757e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[987, 'classID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "021a8cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n",
      "tensor([1], device='cuda:0')\n",
      "Accuracy: 0.00, Total items: 1\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "def inference (model, data):\n",
    "  correct_prediction = 0\n",
    "  total_prediction = 0\n",
    "\n",
    "  # Disable gradient updates\n",
    "  with torch.no_grad():\n",
    "      # Get the input features and target labels, and put them on the GPU\n",
    "      data_1 = data[0].clone().detach()\n",
    "      data_2 = torch.Tensor(data[1])\n",
    "      inputs = data_1.to(device)\n",
    "      label = data_2.to(device)\n",
    "\n",
    "      # Normalize the inputs\n",
    "      inputs_m, inputs_s = inputs.float().mean(), inputs.std()\n",
    "      input = (inputs - inputs_m) / inputs_s\n",
    "      print(data_2)\n",
    "      # Get predictions\n",
    "      model.to(device)\n",
    "      outputs = model(inputs.unsqueeze(0))\n",
    "\n",
    "      # Get the predicted class with the highest score\n",
    "      _, prediction = torch.max(outputs,1)\n",
    "      correct_prediction += (prediction == label).sum().item()\n",
    "      total_prediction += prediction.shape[0]\n",
    "      print(prediction)\n",
    "    \n",
    "  acc = correct_prediction/total_prediction\n",
    "  print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "\n",
    "# Run inference on trained model with the validation set\n",
    "inference(model, processed_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cb8a241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D://Thesis//Emergency Priority//dataset//ambulance_data//ambulance204.wav\n"
     ]
    }
   ],
   "source": [
    "audio_file = data_path + df.loc[5, 'file_path'] + '//' + df.loc[5,'filename']\n",
    "print(audio_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sound-classification",
   "language": "python",
   "name": "sound-classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
